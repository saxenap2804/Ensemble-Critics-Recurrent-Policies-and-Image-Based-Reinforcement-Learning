
This project extends the implementation of the Proximal Policy Optimization (PPO) algorithm to solve complex reinforcement learning tasks, such as stabilizing the inverted pendulum. The project starts with the basic PPO implementation and includes advanced extensions to explore innovative methods like ensemble critics, recurrent policies, and image-based observations.

Features
Implementation of PPO from scratch (without relying on existing PPO libraries).
Custom architecture for policy and critic networks.
Advanced extensions to enhance performance and explore novel use cases.
Visualizations of learning curves, loss curves, and the value landscape.

